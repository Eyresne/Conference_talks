{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "\n",
    "1. What are they?\n",
    "2. What makes them work?\n",
    "3. What is their future?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What are GANs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are neural nets?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've all seen diagrams like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/neural_network_diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what are neural nets, mathematically?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They are:\n",
    "\n",
    "* Universal function approximators\n",
    "* Differentiable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If each layer is written as $a$, $b$, $c$, with weights $V$ and $W$, then the prediction can be written as:\n",
    "\n",
    "$$ P = p(c(b(a(x, V)), W)) $$\n",
    "\n",
    "And the loss can be written as:\n",
    "\n",
    "$$ L = l(p(c(b(a(x, V)), W))) $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does differentiable mean? It means we can compute:\n",
    "\n",
    "$$ \\frac{\\partial l}{\\partial W} $$\n",
    "\n",
    "$$ \\frac{\\partial l}{\\partial V} $$\n",
    "\n",
    "etc. Indeed, this is the information we need to \"train\" the neural network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In addition**, it also means we can compute:\n",
    "\n",
    "$$ \\frac{\\partial l}{\\partial X} $$\n",
    "\n",
    "In other words, how much the loss would change if the _input_ changed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It was _this_ insight that sparked Ian Goodfellow to investigate GANs:\n",
    "\n",
    "Could a machine learning algorithm use this information to learn how to \"trick\" another algorithm by producing examples that reduced this loss?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Origin story"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ian Goodfellow and Yoshua Bengio are about to run a speech synthesis contest. They want to have a discriminator network that could listen to artificially generated speech and decide if it was real or not. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They conclude that people will just game the system by generating examples that will fool this particular discriminator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, Ian Goodfellow was in a bar one night, and asked the question: can this be changed by the discriminator learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How could you do it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First: randomly generate a feature vector; feed the feature vector through a randomly initialized neural network to produce an output image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\begin{bmatrix}z_1 \\\\\n",
    "                  z_2 \\\\\n",
    "                  ... \\\\\n",
    "                  z_{100}\n",
    "                  \\end{bmatrix} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/gan_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's denote the matrix of pixels in this image $X$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, feed this image (matrix of pixels X) into a second network and get a prediction:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/gan_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this loss to train the generator. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Critically, also compute $$ \\frac{\\partial L}{\\partial X} $$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, update the generator with $$ -\\frac{\\partial L}{\\partial X} $$\n",
    "\n",
    "negative because we want the generator to be continually making the discriminator more likely to say that its images are real."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this to update the weights of the generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/gan_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate _new_ random noise, and repeat the process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's missing?\n",
    "\n",
    "This will train the generator to generate good fake images, but it will likely result in the discriminator not being a very smart classifier since we only gave it one of the two classes it is trying to classify. So, we'll have to give it images from the true class as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/gans_4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Original GitHub repo with Ian Goodfellow's code](https://github.com/goodfeli/galatea/commit/d960968919b0856ba6753198a0e035228d7c03e6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's code one up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See notebook here [here](GAN_example/dlnd_face_generation.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've all seen diagrams like this in the context of convolutional neural nets:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/AlexNet_0.jpg)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What's really going on here?\n",
    "\n",
    "Let's say we have an input layer of size $[224x224x3]$, as we do in ImageNet. This next layer seems to be $96$ deep. What does that mean?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "For each of 96 _filters_, the following happens:\n",
    "\n",
    "For each of the 3 _input channels_, the _filter_, which happens to be dimension $11 x 11$ in this case, is slid over the image, \"detecting the presence of different features\" at each location. We'll call the image that results the \"output image\".\n",
    "\n",
    "At the next layer, the values of these three output images are summed together to generate the first of 96 output images in the following layer. \n",
    "\n",
    "In addition, the three filters - the one slid over the red, green, and blue color channels - can be combined together and visualized as if they were a mini 11x11 image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/AlexNet_filt1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "That's a review of convolutions:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Point is: for each convolution, the **size of the output** from convolving a filter over an image will be a function of:\n",
    "\n",
    "1. The input size, $I$\n",
    "2. The filter size, $F$\n",
    "3. The stride, $S$\n",
    "4. The padding, $P$\n",
    "\n",
    "There are formulas relating these quantities that you can look up; however, I think it's best to just reason through what the output shape should be each time."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What does this have to do with GANs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Doing these convolutions is relatively straightforward - but how do we do deconvolutions?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Meaning, if we start with a $4x4$ input, how do we scale it up to say, $28x28$?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Well, we can represent convolutions by a matrix transformation. See [here](http://deeplearning.net/software/theano/tutorial/conv_arithmetic.html#convolution-as-a-matrix-operation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After all, a convolution that transforms a $4x4$ image into a $2x2$ is a linear transformation that can be represented by a $16x4$ matrix."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To \"deconvolve\" a $2x2$ matrix into a $4x4$, we would multiply it by the inverse of the original matrix."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "def generator(z, out_channel_dim, is_train=True):\n",
    "    \"\"\"\n",
    "    Create the generator network\n",
    "    :param z: Input z\n",
    "    :param out_channel_dim: The number of channels in the output image\n",
    "    :param is_train: Boolean if generator is being used for training\n",
    "    :return: The tensor output of the generator\n",
    "    \"\"\"\n",
    "    # TODO: Implement Function\n",
    "    with tf.variable_scope('generator', reuse=not is_train):\n",
    "        # First fully connected layer\n",
    "        x1 = tf.layers.dense(z, 4*4*512)\n",
    "#         # Reshape it to start the convolutional stack\n",
    "        x1 = tf.reshape(x1, (-1, 4, 4, 512))\n",
    "        x1 = tf.layers.batch_normalization(x1, training=is_train)\n",
    "        x1 = tf.maximum(0.2 * x1, x1)\n",
    "\n",
    "        x2 = tf.layers.conv2d_transpose(x1, 256, 4, strides=1, padding='same')\n",
    "        x2 = tf.layers.batch_normalization(x2, training=is_train)\n",
    "        x2 = tf.maximum(0.2 * x2, x2)\n",
    "\n",
    "#         x3 = tf.layers.conv2d_transpose(x2, 128, 5, strides=2, padding='same')\n",
    "#         x3 = tf.layers.batch_normalization(x3, training=is_train)\n",
    "#         x3 = tf.maximum(0.2 * x3, x3)\n",
    "\n",
    "#         logits = tf.layers.conv2d_transpose(x3, out_channel_dim, 5, strides=2, padding='same')\n",
    "\n",
    "#         out = tf.tanh(logits)\n",
    "    \n",
    "    return x2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from copy import deepcopy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from unittest import mock\n",
    "class TmpMock():\n",
    "    \"\"\"\n",
    "    Mock a attribute.  Restore attribute when exiting scope.\n",
    "    \"\"\"\n",
    "    def __init__(self, module, attrib_name):\n",
    "        self.original_attrib = deepcopy(getattr(module, attrib_name))\n",
    "        setattr(module, attrib_name, mock.MagicMock())\n",
    "        self.module = module\n",
    "        self.attrib_name = attrib_name\n",
    "\n",
    "    def __enter__(self):\n",
    "        return getattr(self.module, self.attrib_name)\n",
    "\n",
    "    def __exit__(self, type, value, traceback):\n",
    "        setattr(self.module, self.attrib_name, self.original_attrib)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(?, 4, 4, 256)\n"
     ]
    }
   ],
   "source": [
    "with TmpMock(tf, 'variable_scope') as mock_variable_scope:\n",
    "    z = tf.placeholder(tf.float32, [None, 100])\n",
    "    out_channel_dim = 3\n",
    "    output = generator(z, out_channel_dim)\n",
    "    print(output.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, let's review two common terms when it comes to \"padding\" in TensorFlow or convolutional neural nets more generally:\n",
    "\n",
    "* \"Same\" padding means pad the input so that the output shape is the same as the input shape. If we have a 5x5 kernel, that means pad two units on the edges of the image.\n",
    "* \"Valid\" padding means don't apply any padding - on a forward convolution pass, having no padding means the output image will be smaller than the input image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So, why is it that applying a `conv_2d_transpose` operation to a $4x4$ image with `valid` padding results in a $7x7$ whereas applying that operation with `same` padding results in a $4x4$? On the forward pass, this is easy to reason about, but on the backwards pass it is trickier."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The reason is that deconvolutions are just inverses of convolutions - and applying a convolution of kernel size 4 and stride 1 with `valid` padding to a 7x7 image would result in a 4x4. Similar reasoning applys to same padding."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Getting the dimensions right on these deconvolutions is one of the trickiest parts of getting GANs to work!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DC-GAN Architecture\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three tricks:\n",
    "\n",
    "## Deconvolutions:\n",
    "\n",
    "Architecture:\n",
    "\n",
    "1. Start with random noise vector of length 100\n",
    "2. Begin by transforming it to a fully connected layer with shape $4*4*512$, say.\n",
    "3. Perform deconvolution steps to apply a bunch of filters to these images to produce images of the shape you want, say 28 x 28."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go through an illustration here:\n",
    "\n",
    "[Theano documentation](http://deeplearning.net/software/theano/tutorial/conv_arithmetic.html)\n",
    "\n",
    "What do deconvolution operations do? \n",
    "Convolutions can be represented as matrix multiplications. \n",
    "Deconvolutions are just the inverse of those matrix multiplications.\n",
    "So, when choosing our filter, padding, and stride of an inverse convolution operation, what output would result?\n",
    "The answer is that the resulting output will be the one that would produce the input that we give this layer.\n",
    "\n",
    "Let's look at an example. If we give a Conv 2D transpose a 4x4, and do an inverse convolution operation with:\n",
    "\n",
    "Stride 1\n",
    "Filter size 4\n",
    "Valid padding.\n",
    "\n",
    "We get a 7x7. Why?\n",
    "\n",
    "Consider doing this operation on a 7x7. It is clear that we'll get a 4x4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See [here](http://www.deeplearningbook.org/contents/optimization.html), and especially the batch normalization lesson in the Udacity repo. This guy actually figured out the gradients for batch normalization. [here](http://kratzert.github.io/2016/02/12/understanding-the-gradient-flow-through-the-batch-normalization-layer.html). Also: [unbelievable](https://github.com/cthorey/CS231)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is their future?\n",
    "\n",
    "## Applications:\n",
    "\n",
    "* Drug discovery\n",
    "\n",
    "* Semi-supervised learning\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
