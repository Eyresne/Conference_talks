{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Table of contents\n",
    "\n",
    "1. What are they?\n",
    "2. What makes them work?\n",
    "3. What is their future?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What are GANs?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## What are neural nets?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We've all seen diagrams like this:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/neural_network_diagram.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "But what are neural nets, mathematically?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They are:\n",
    "\n",
    "* Universal function approximators\n",
    "* Differentiable"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If each layer is written as $a$, $b$, $c$, with weights $V$ and $W$, then the prediction can be written as:\n",
    "\n",
    "$$ P = p(c(b(a(x, V)), W)) $$\n",
    "\n",
    "And the loss can be written as:\n",
    "\n",
    "$$ L = l(p(c(b(a(x, V)), W))) $$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "What does differentiable mean? It means we can compute:\n",
    "\n",
    "$$ \\frac{\\partial l}{\\partial W} $$\n",
    "\n",
    "$$ \\frac{\\partial l}{\\partial V} $$\n",
    "\n",
    "etc. Indeed, this is the information we need to \"train\" the neural network. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**In addition**, it also means we can compute:\n",
    "\n",
    "$$ \\frac{\\partial l}{\\partial X} $$\n",
    "\n",
    "In other words, how much the loss would change if the _input_ changed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It was _this_ insight that sparked Ian Goodfellow to investigate GANs:\n",
    "\n",
    "Could a machine learning algorithm use this information to learn how to \"trick\" another algorithm by producing examples that reduced this loss?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Origin story"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ian Goodfellow and Yoshua Bengio are about to run a speech synthesis contest. They want to have a discriminator network that could listen to artificially generated speech and decide if it was real or not. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "They conclude that people will just game the system by generating examples that will fool this particular discriminator."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, Ian Goodfellow was in a bar one night, and asked the question: can this be changed by the discriminator learning?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## How could you do it?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Part 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First: randomly generate a feature vector; feed the feature vector through a randomly initialized neural network to produce an output image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "$$ \\begin{bmatrix}z_1 \\\\\n",
    "                  z_2 \\\\\n",
    "                  ... \\\\\n",
    "                  z_{100}\n",
    "                  \\end{bmatrix} $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/gan_1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's denote the matrix of pixels in this image $X$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, feed this image (matrix of pixels X) into a second network and get a prediction:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/gan_2.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this loss to train the generator. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Critically, also compute $$ \\frac{\\partial L}{\\partial X} $$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Then, update the generator with $$ -\\frac{\\partial L}{\\partial X} $$\n",
    "\n",
    "negative because we want the generator to be continually making the discriminator more likely to say that its images are real."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Use this to update the weights of the generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/gan_3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate _new_ random noise, and repeat the process."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What's missing?\n",
    "\n",
    "This will train the generator to generate good fake images, but it will likely result in the discriminator not being a very smart classifier since we only gave it one of the two classes it is trying to classify. So, we'll have to give it images from the true class as well."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![](img/gans_4.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[Original GitHub repo with Ian Goodfellow's code](https://github.com/goodfeli/galatea/commit/d960968919b0856ba6753198a0e035228d7c03e6)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Let's code one up"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See notebook here [here](GAN_example/dlnd_face_generation.ipynb)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Convolutions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# DC-GAN Architecture\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Three tricks:\n",
    "\n",
    "## Deconvolutions:\n",
    "\n",
    "Architecture:\n",
    "\n",
    "1. Start with random noise vector of length 100\n",
    "2. Begin by transforming it to a fully connected layer with shape $4*4*512$, say.\n",
    "3. Perform deconvolution steps to apply a bunch of filters to these images to produce images of the shape you want, say 28 x 28."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's go through an illustration here:\n",
    "\n",
    "[Theano documentation](http://deeplearning.net/software/theano/tutorial/conv_arithmetic.html)\n",
    "\n",
    "What do deconvolution operations do? \n",
    "Convolutions can be represented as matrix multiplications. \n",
    "Deconvolutions are just the inverse of those matrix multiplications.\n",
    "So, when choosing our filter, padding, and stride of an inverse convolution operation, what output would result?\n",
    "The answer is that the resulting output will be the one that would produce the input that we give this layer.\n",
    "\n",
    "Let's look at an example. If we give a Conv 2D transpose a 4x4, and do an inverse convolution operation with:\n",
    "\n",
    "Stride 1\n",
    "Filter size 4\n",
    "Valid padding.\n",
    "\n",
    "We get a 7x7. Why?\n",
    "\n",
    "Consider doing this operation on a 7x7. It is clear that we'll get a 4x4."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Batch normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "See [here](http://www.deeplearningbook.org/contents/optimization.html), and especially the batch normalization lesson in the Udacity repo. This guy actually figured out the gradients for batch normalization. [here](http://kratzert.github.io/2016/02/12/understanding-the-gradient-flow-through-the-batch-normalization-layer.html). Also: [unbelievable](https://github.com/cthorey/CS231)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# What is their future?\n",
    "\n",
    "## Applications:\n",
    "\n",
    "* Drug discovery\n",
    "\n",
    "* Semi-supervised learning\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
